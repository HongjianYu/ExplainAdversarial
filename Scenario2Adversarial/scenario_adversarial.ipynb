{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.multiprocessing as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pytorch_grad_cam import CAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import pickle\n",
    "import shelve\n",
    "import heapq\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/homes/gws/hjyu/masksearch/MaskSearchDemo/Scenario2Adversarial')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set main path to scenario root directory\n",
    "main = Path(\".\").resolve()\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/hjyu/miniconda3/envs/masksearch/lib/python3.9/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load(main/\"checkpoints/resnet50_imagenette.pth\")\n",
    "model = resnet50()\n",
    "\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"data\"\n",
    "num_processes = mp.cpu_count() // 2\n",
    "num_processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagenettePath(datasets.Imagenette):\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self._samples[idx]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label, path\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image\n",
    "\n",
    "def convert(input_image, multiply=False, BGR=False):\n",
    "    multiplier = 255.0 if multiply else 1.0\n",
    "    image = np.moveaxis(input_image.detach().cpu().numpy() * multiplier, 0, 2)\n",
    "    if BGR:\n",
    "        image = image[:, :, ::-1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = False\n",
    "transform=transforms.Compose([transforms.ToTensor(), transforms.Resize((400, 600))])\n",
    "dataset = ImagenettePath(main/dataset_name, size='full',\n",
    "                         split='val', transform=transform, download=download)\n",
    "chunk = len(dataset) // num_processes\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=chunk, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_attack(images, targets, paths, criterion, epsilon):\n",
    "    for image, target, path in zip(images, targets, paths):\n",
    "        image, target = image[None, :, :, :], torch.tensor([target]).to(device)\n",
    "        image.requires_grad = True\n",
    "        y_hat = model(image)\n",
    "        prediction = y_hat.argmax(1)\n",
    "        if prediction.item() != target.item():\n",
    "            continue\n",
    "        loss = criterion(y_hat, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        perturbed_image = fgsm_attack(image, epsilon, image.grad)\n",
    "        path_split = path.split(\"/\")\n",
    "        path_attacking = main/dataset_name/\"imagenette2\"/\"val\"/path_split[-2]/(path_split[-1][:-5] + \"_attacked.JPEG\")\n",
    "        cv2.imwrite(str(path_attacking), convert(perturbed_image[0], multiply=True, BGR=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epsilon = 0.05\n",
    "\n",
    "for images, targets, paths in loader:\n",
    "    torch.set_num_threads(1)\n",
    "    model.share_memory()\n",
    "    p = mp.Process(target=process_attack, args=(images.to(device), targets.to(device), paths, criterion, epsilon))\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_folder_name = \"serialized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(), transforms.Resize((400, 600))])\n",
    "dataset = ImagenettePath(main/dataset_name, size='full',\n",
    "                         split='val', transform=transform, download=False)\n",
    "batch_size = len(dataset) // num_processes\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_serialized(images, targets, paths, q, i):\n",
    "    images_local = []\n",
    "    cams_local = []\n",
    "    correctness_local= []\n",
    "    attack_local = []\n",
    "\n",
    "    if i < len(images):\n",
    "        for image, target, path in zip(images[i:i+1], targets[i:i+1], paths[i:i+1]):\n",
    "            target_layer = model.layer4[-1]\n",
    "            cam = CAM(model=model,  target_layer=target_layer, use_cuda=torch.cuda.is_available())\n",
    "            image, target = image[None, :, :, :], torch.tensor([target]).to(device)\n",
    "\n",
    "            image.requires_grad = False\n",
    "            prediction = model(image).argmax(1)\n",
    "\n",
    "            image.requires_grad = True\n",
    "            grayscale_cam = cam(input_tensor=image, target_category=target.item(), method=\"gradcam\")\n",
    "            converted_image = convert(image[0])\n",
    "\n",
    "            images_local.append(converted_image)\n",
    "            cams_local.append(grayscale_cam)\n",
    "            correctness_local.append(prediction.item() == target.item())\n",
    "            attack_local.append(\"attack\" in path)\n",
    "\n",
    "    q.put((images_local, cams_local, correctness_local, attack_local))\n",
    "    print(f\"{os.getpid()} Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_global = []\n",
    "cams_global = []\n",
    "correctness_global = []\n",
    "attack_global = []\n",
    "\n",
    "with tqdm(range(batch_size), desc=f\"Load Saliency Maps\", total=batch_size) as tq:\n",
    "    for i in tq:\n",
    "        processes = []\n",
    "        q = mp.Queue()\n",
    "\n",
    "        for images, targets, paths in loader:\n",
    "            torch.set_num_threads(1)\n",
    "            model.share_memory()\n",
    "            p = mp.Process(target=process_serialized, args=(images.to(device), targets.to(device), paths, q, i))\n",
    "            processes.append(p)\n",
    "            p.start()\n",
    "        for p in processes:\n",
    "            images_local, cams_local, correctness_local, attack_local = q.get()\n",
    "            images_global.extend(images_local)\n",
    "            cams_global.extend(cams_local)\n",
    "            correctness_global.extend(correctness_local)\n",
    "            attack_global.extend(attack_local)\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "image_file = open(serialized_folder_name + \"/image_data.pkl\", \"wb\")\n",
    "cam_file = open(serialized_folder_name + \"/cam_data.pkl\", \"wb\")\n",
    "correctness_file = open(serialized_folder_name + \"/correctness_data.pkl\", \"wb\")\n",
    "attack_file = open(serialized_folder_name + \"/attack_data.pkl\", \"wb\")\n",
    "\n",
    "pickle.dump(images_global, image_file, pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(cams_global, cam_file, pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(correctness_global, correctness_file, pickle.HIGHEST_PROTOCOL)\n",
    "pickle.dump(attack_global, attack_file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "image_file.close()\n",
    "cam_file.close()\n",
    "correctness_file.close()\n",
    "attack_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dispersion(cam, threshold=(0.3, 0.45)):\n",
    "    if isinstance(threshold, tuple):\n",
    "        assert len(threshold) == 2\n",
    "        return ((cam > threshold[0]) & (cam <= threshold[1])).sum()\n",
    "    else:\n",
    "        return (cam > threshold).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dispersion scores\n",
    "dispersion_data = []\n",
    "\n",
    "cam_file = open(serialized_folder_name + \"/cam_data.pkl\", \"rb\")\n",
    "dispersion_file = open(serialized_folder_name + \"/dispersion_data.pkl\", \"wb\")\n",
    "\n",
    "cam_data = pickle.load(cam_file)\n",
    "\n",
    "for cam in cam_data:\n",
    "    dispersion_data.append(compute_dispersion(cam, threshold=(0.2, 0.4)))\n",
    "\n",
    "pickle.dump(dispersion_data, dispersion_file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "cam_file.close()\n",
    "dispersion_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification rate in 7768 images: 0.09191555097837278\n",
      "Misclassification rate in top 20: 0.0\n",
      "Attack rate in 7768 images: 0.49472193614830073\n",
      "Attack rate in top 20: 0.7\n",
      "dispersion=119911, classification=True, attack=True\n",
      "dispersion=112494, classification=True, attack=False\n",
      "dispersion=112244, classification=True, attack=True\n",
      "dispersion=111636, classification=True, attack=True\n",
      "dispersion=109952, classification=True, attack=True\n",
      "dispersion=109779, classification=True, attack=True\n",
      "dispersion=109006, classification=True, attack=True\n",
      "dispersion=108011, classification=True, attack=True\n",
      "dispersion=107631, classification=True, attack=False\n",
      "dispersion=107168, classification=True, attack=False\n",
      "dispersion=106790, classification=True, attack=False\n",
      "dispersion=104623, classification=True, attack=True\n",
      "dispersion=103092, classification=True, attack=True\n",
      "dispersion=103010, classification=True, attack=False\n",
      "dispersion=102660, classification=True, attack=True\n",
      "dispersion=102485, classification=True, attack=True\n",
      "dispersion=102216, classification=True, attack=False\n",
      "dispersion=100534, classification=True, attack=True\n",
      "dispersion=99290, classification=True, attack=True\n",
      "dispersion=98986, classification=True, attack=True\n"
     ]
    }
   ],
   "source": [
    "# Load top-k results\n",
    "image_file = open(serialized_folder_name + \"/image_data.pkl\", \"rb\")\n",
    "cam_file = open(serialized_folder_name + \"/cam_data.pkl\", \"rb\")\n",
    "correctness_file = open(serialized_folder_name + \"/correctness_data.pkl\", \"rb\")\n",
    "attack_file = open(serialized_folder_name + \"/attack_data.pkl\", \"rb\")\n",
    "dispersion_file = open(serialized_folder_name + \"/dispersion_data.pkl\", \"rb\")\n",
    "\n",
    "image_data = pickle.load(image_file)\n",
    "cam_data = pickle.load(cam_file)\n",
    "correctness_data = pickle.load(correctness_file)\n",
    "attack_data = pickle.load(attack_file)\n",
    "dispersion_data = pickle.load(dispersion_file)\n",
    "\n",
    "k = 20\n",
    "top_k = heapq.nlargest(k, zip(image_data, cam_data, correctness_data, attack_data, dispersion_data), key=itemgetter(4))\n",
    "print(f\"Misclassification rate in {len(correctness_data)} images: {1 - sum(correctness_data) / len(correctness_data)}\")\n",
    "print(f\"Misclassification rate in top {k}: {1 - sum([entry[2] for entry in top_k]) / len(top_k)}\")\n",
    "print(f\"Attack rate in {len(attack_data)} images: {sum(attack_data) / len(attack_data)}\")\n",
    "print(f\"Attack rate in top {k}: {sum([entry[3] for entry in top_k]) / len(top_k)}\")\n",
    "\n",
    "i = 0\n",
    "for image, cam, correctness, attack, dispersion in top_k:\n",
    "    i += 1\n",
    "    cam_display = show_cam_on_image(image, cam)\n",
    "    cv2.imwrite(str(main/\"results\"/f\"cam_display_{i}.JPEG\"), cam_display)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(cam_display)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    print(f\"dispersion={dispersion}, classification={correctness}, attack={attack}\")\n",
    "    if i > 20:\n",
    "        break\n",
    "\n",
    "image_file.close()\n",
    "cam_file.close()\n",
    "correctness_file.close()\n",
    "attack_file.close()\n",
    "dispersion_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_map = shelve.open(serialized_folder_name + \"/cam_map\")\n",
    "cam_file = open(serialized_folder_name + \"/cam_data.pkl\", \"rb\")\n",
    "cam_data = pickle.load(cam_file)\n",
    "for i, cam in enumerate(cam_data):\n",
    "    cam_map[f\"{i}\"] = cam\n",
    "cam_file.close()\n",
    "cam_map.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masksearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
